{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Transfer Learning Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimheeseo/2022_AI_SW_Programmingstudy/blob/main/Pytorch_Transfer_Learning_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlflXdFQikh1",
        "outputId": "50de44b2-2dfe-4cc0-dc23-f83959aa8ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:  1.10.0+cu111\n",
            "Torchvision Version:  0.11.1+cu111\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 다운로드\n",
        "\n",
        "- 데이터 셋에 관한 설명\n",
        "\n",
        "  https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "- 10개의 다른 클래스의 데이터를 포함"
      ],
      "metadata": {
        "id": "DQwKcoF_iybt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing modules\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True, \n",
        "                                             transform=transform,\n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                            train=False, \n",
        "                                            transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=256, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=256, \n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVdQN6-1ipVq",
        "outputId": "15920991-4838-4e53-f418-238733844a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파라미터 설정\n",
        "\n",
        "- pytorch에서 제공하는 pretrained 모델의 종류\n",
        "\n",
        "  https://pytorch.org/vision/stable/models.html"
      ],
      "metadata": {
        "id": "e7gh9vo6myGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes in the dataset\n",
        "num_classes = 10\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"resnet\"\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15"
      ],
      "metadata": {
        "id": "7PczWcQ0j3c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 훈련과 검증 코드"
      ],
      "metadata": {
        "id": "4Zp4j4PFnIZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # model의 종류가 inception일 때만 작동\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "metadata": {
        "id": "hIUeh-sSj52_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_model(model_name, num_classes, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-Vun3EmkFZc",
        "outputId": "1758ddcc-66a7-47af-b000-43d08f3fe999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bvaZJNeUkSW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "o4pFaJZVkcZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders_dict = {'train': train_loader, 'val': test_loader}\n",
        "\n",
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQqwvpZnkf8w",
        "outputId": "6abefba3-1c57-412d-e8f1-af6759cb3a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.5054 Acc: 0.4689\n",
            "val Loss: 1.1166 Acc: 0.6046\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 1.0287 Acc: 0.6377\n",
            "val Loss: 0.9386 Acc: 0.6718\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.8886 Acc: 0.6893\n",
            "val Loss: 0.8382 Acc: 0.7089\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.8035 Acc: 0.7172\n",
            "val Loss: 0.7664 Acc: 0.7359\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.7388 Acc: 0.7408\n",
            "val Loss: 0.7284 Acc: 0.7482\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.6978 Acc: 0.7553\n",
            "val Loss: 0.7025 Acc: 0.7597\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.6575 Acc: 0.7712\n",
            "val Loss: 0.6662 Acc: 0.7713\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.6218 Acc: 0.7818\n",
            "val Loss: 0.6469 Acc: 0.7807\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.5979 Acc: 0.7898\n",
            "val Loss: 0.6286 Acc: 0.7867\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.5712 Acc: 0.7985\n",
            "val Loss: 0.6199 Acc: 0.7881\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.5508 Acc: 0.8088\n",
            "val Loss: 0.6041 Acc: 0.7939\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.5308 Acc: 0.8131\n",
            "val Loss: 0.6030 Acc: 0.7941\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.5131 Acc: 0.8198\n",
            "val Loss: 0.5809 Acc: 0.8032\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.4935 Acc: 0.8262\n",
            "val Loss: 0.5795 Acc: 0.8032\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.4748 Acc: 0.8331\n",
            "val Loss: 0.5687 Acc: 0.8068\n",
            "\n",
            "Training complete in 9m 56s\n",
            "Best val Acc: 0.806800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the non-pretrained version of the model used for this run\n",
        "scratch_model,_ = initialize_model(model_name, num_classes, use_pretrained=False)\n",
        "scratch_model = scratch_model.to(device)\n",
        "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
        "scratch_criterion = nn.CrossEntropyLoss()\n",
        "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
        "\n",
        "# Plot the training curves of validation accuracy vs. number\n",
        "#  of training epochs for the transfer learning method and\n",
        "#  the model trained from scratch\n",
        "ohist = []\n",
        "shist = []\n",
        "\n",
        "ohist = [h.cpu().numpy() for h in hist]\n",
        "shist = [h.cpu().numpy() for h in scratch_hist]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
        "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xr_s-ajNlKnV",
        "outputId": "4a5db797-e38c-4fa3-8891-cacd5e135a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 1.9172 Acc: 0.2984\n",
            "val Loss: 1.6314 Acc: 0.4010\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 1.5922 Acc: 0.4104\n",
            "val Loss: 1.8483 Acc: 0.3945\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.4813 Acc: 0.4562\n",
            "val Loss: 1.4402 Acc: 0.4749\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.4089 Acc: 0.4848\n",
            "val Loss: 1.3949 Acc: 0.4853\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 1.3392 Acc: 0.5140\n",
            "val Loss: 1.3069 Acc: 0.5259\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 1.2743 Acc: 0.5385\n",
            "val Loss: 1.4119 Acc: 0.5095\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 1.2282 Acc: 0.5575\n",
            "val Loss: 1.3155 Acc: 0.5358\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 1.1896 Acc: 0.5712\n",
            "val Loss: 1.5186 Acc: 0.5061\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 1.1507 Acc: 0.5855\n",
            "val Loss: 1.1237 Acc: 0.5917\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 1.1143 Acc: 0.5996\n",
            "val Loss: 1.1223 Acc: 0.6028\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 1.0898 Acc: 0.6086\n",
            "val Loss: 1.1274 Acc: 0.6026\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 1.0581 Acc: 0.6206\n",
            "val Loss: 1.1002 Acc: 0.6050\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 1.0305 Acc: 0.6301\n",
            "val Loss: 1.1141 Acc: 0.6116\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 1.0109 Acc: 0.6399\n",
            "val Loss: 1.0798 Acc: 0.6157\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.9872 Acc: 0.6489\n",
            "val Loss: 1.2517 Acc: 0.5889\n",
            "\n",
            "Training complete in 9m 55s\n",
            "Best val Acc: 0.615700\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WTEVtDPcowOR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
